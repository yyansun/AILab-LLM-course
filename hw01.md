# 书生·浦语全链条开源开放体系

### 1.InternLM2:回归语言建模的本职
- <img src="images/hw0110.png">
---
### 2.从模型到应用典型流程
- <img src="images/hw0111.png">
---
### 3.全链条开源体系
<img src="images/hw0101.png">

#### 1.数据
- 数据集获取：OpenDataLab
- <img src="images/hw0102.png">
---

#### 2.预训练
- <img src="images/hw0103.png">
---

#### 3.微调
- **增量续训**和**有监督微调**
- **增量续训：**
  - 使用场景：让基座模型学习到一些新知识
  - 训练数据：文章、书籍、代码
- **有监督微调：**
  - 使用场景：让模型学会理解各种指令进行对话，或者注入少量领域知识
  - 训练数据：高质量的对话、问答数据
- **微调框架XTuner:**
- <img src="images/hw0104.png">
- <img src="images/hw0105.png">
---

#### 4.评测
- OpenCompass2.0司南大模型评测体系
- CompassKit:大模型评测全栈工具链
- <img src="images/hw0109.png">
---

#### 5.部署：LMDeploy
- LMDeploy提供大模型在GPU上部署的全流程解决方案，包括模型轻量化、推理和服务
- <img src="images/hw0106.png">
---

#### 6.智能体框架：Lagent AGentLego
- 轻量级智能体框架Lagent:
  - 支持多种类型的智能体能力
  - 灵活支持多种大语言模型
  - 简单易拓展，支持丰富的工具
- <img src="images/hw0107.png">
- 多模态智能体工具箱AgentLego
- <img src="images/hw0108.png">
---

### 论文阅读
#### 主要特点和创新
1. **预训练过程：**
   - **数据多样性：** 预训练数据包括文本、代码和长上下文数据，确保模型能够处理各种类型的输入。
   - **长上下文建模：** 初始训练使用4k标记，随后扩展到32k标记，以增强模型的长上下文处理能力。特别是在200k“针在干草堆”测试中表现优异。
   - **预训练细节：** 详细描述了数据准备过程，包括文本、代码和长上下文数据的处理，以及分词和超参数设置。

2. **微调和对齐：**
   - **监督微调（SFT）：** 通过监督微调提高模型在具体任务上的表现。
   - **在线人类反馈强化学习（COOL RLHF）：** 引入了一种新颖的在线人类反馈强化学习策略，通过条件奖励模型解决人类偏好冲突和奖励作弊问题。
   - **长上下文微调：** 在SFT和RLHF过程中构建相应的32k数据，进一步提升模型的长上下文处理能力。

3. **模型版本：**
   - **多样化模型发布：** 发布了不同训练阶段和大小的模型，包括1.8B、7B和20B参数的版本，以便社区分析模型在SFT和RLHF训练前后的变化。

#### 性能和评估
- **全面评估：** InternLM2在6个维度和30个基准测试中表现出色，展示了其在语言理解、推理、数学和编程等方面的强大能力。
- **主观评估：** 模型在英文和中文的主观评估中均表现优异，特别是在长上下文和工具利用等方面。
- **对齐性能：** 使用COOL RLHF显著提升了模型在各种主观对话评估中的表现，并进行了条件奖励模型的消融研究。
